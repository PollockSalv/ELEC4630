{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of variational_autoencoder.ipynb","provenance":[{"file_id":"https://github.com/lovellbrian/ELEC4630/blob/master/variational_autoencoder.ipynb","timestamp":1586231677143}],"collapsed_sections":[],"authorship_tag":"ABX9TyNE6VN1epfUnxw1jquIRf7s"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Zo29OC5Gz7Zk","colab_type":"text"},"source":["#ELEC4630\n","\n","#Example of VAE on MNIST dataset using MLP\n","\n","The VAE has a modular design. The encoder, decoder and VAE\n","are 3 models that share weights. After training the VAE model,\n","the encoder can be used to generate latent vectors.\n","The decoder can be used to generate MNIST digits by sampling the\n","latent vector from a Gaussian distribution with mean = 0 and std = 1.\n","\n","# Reference\n","\n","[1] Kingma, Diederik P., and Max Welling.\n","\"Auto-Encoding Variational Bayes.\"\n","https://arxiv.org/abs/1312.6114\n","'''"]},{"cell_type":"code","metadata":{"id":"E2IhvZA1vRJn","colab_type":"code","outputId":"5858758b-bcf0-4611-bbc1-c043faff7009","executionInfo":{"status":"ok","timestamp":1586236033322,"user_tz":-600,"elapsed":2966,"user":{"displayName":"Brian Lovell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLJTplecV69EHI4U7DWw1Wtt_x89tJk7nRBtFO=s64","userId":"09256562344483711914"}},"colab":{"base_uri":"https://localhost:8080/","height":92}},"source":["# Tensorflow 1.x compatibility \n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nBefO7gkyA00","colab_type":"code","colab":{}},"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","import datetime\n","# Clear any logs from previous runs\n","!rm -rf ./logs/ "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X1gSrD4siQ7-","colab_type":"code","outputId":"23ce2466-efc2-474d-e464-3bffdd81f2b1","executionInfo":{"status":"error","timestamp":1586231617988,"user_tz":-600,"elapsed":501297,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","# from layers import Lambda, Input, Dense\n","# from keras.models import Model\n","# from keras.datasets import mnist\n","# from keras.losses import mse, binary_crossentropy\n","# from keras.utils import plot_model\n","\n","from tensorflow.compat.v1.keras.layers import Lambda, Input, Dense\n","from tensorflow.compat.v1.keras.models import Model\n","from tensorflow.compat.v1.keras.datasets import mnist\n","from tensorflow.compat.v1.keras.losses import mse, binary_crossentropy\n","from tensorflow.compat.v1.keras.utils import plot_model\n","from tensorflow.compat.v1.keras import backend as K\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import argparse\n","import os\n","\n","\n","# reparameterization trick\n","# instead of sampling from Q(z|X), sample epsilon = N(0,I)\n","# z = z_mean + sqrt(var) * epsilon\n","def sampling(args):\n","    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n","\n","    # Arguments\n","        args (tensor): mean and log of variance of Q(z|X)\n","\n","    # Returns\n","        z (tensor): sampled latent vector\n","    \"\"\"\n","\n","    z_mean, z_log_var = args\n","    batch = K.shape(z_mean)[0]\n","    dim = K.int_shape(z_mean)[1]\n","    # by default, random_normal has mean = 0 and std = 1.0\n","    epsilon = K.random_normal(shape=(batch, dim))\n","    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n","\n","\n","def plot_results(models,\n","                 data,\n","                 batch_size=128,\n","                 model_name=\"vae_mnist\"):\n","    \"\"\"Plots labels and MNIST digits as a function of the 2D latent vector\n","\n","    # Arguments\n","        models (tuple): encoder and decoder models\n","        data (tuple): test data and label\n","        batch_size (int): prediction batch size\n","        model_name (string): which model is using this function\n","    \"\"\"\n","\n","    encoder, decoder = models\n","    x_test, y_test = data\n","    os.makedirs(model_name, exist_ok=True)\n","\n","    filename = os.path.join(model_name, \"vae_mean.png\")\n","    # display a 2D plot of the digit classes in the latent space\n","    z_mean, _, _ = encoder.predict(x_test,\n","                                   batch_size=batch_size)\n","    plt.figure(figsize=(12, 10))\n","    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n","    plt.colorbar()\n","    plt.xlabel(\"z[0]\")\n","    plt.ylabel(\"z[1]\")\n","    plt.savefig(filename)\n","    plt.show()\n","\n","    filename = os.path.join(model_name, \"digits_over_latent.png\")\n","    # display a 30x30 2D manifold of digits\n","    n = 30\n","    digit_size = 28\n","    figure = np.zeros((digit_size * n, digit_size * n))\n","    # linearly spaced coordinates corresponding to the 2D plot\n","    # of digit classes in the latent space\n","    grid_x = np.linspace(-4, 4, n)\n","    grid_y = np.linspace(-4, 4, n)[::-1]\n","\n","    for i, yi in enumerate(grid_y):\n","        for j, xi in enumerate(grid_x):\n","            z_sample = np.array([[xi, yi]])\n","            x_decoded = decoder.predict(z_sample)\n","            digit = x_decoded[0].reshape(digit_size, digit_size)\n","            figure[i * digit_size: (i + 1) * digit_size,\n","                   j * digit_size: (j + 1) * digit_size] = digit\n","\n","    plt.figure(figsize=(10, 10))\n","    start_range = digit_size // 2\n","    end_range = (n - 1) * digit_size + start_range + 1\n","    pixel_range = np.arange(start_range, end_range, digit_size)\n","    sample_range_x = np.round(grid_x, 1)\n","    sample_range_y = np.round(grid_y, 1)\n","    plt.xticks(pixel_range, sample_range_x)\n","    plt.yticks(pixel_range, sample_range_y)\n","    plt.xlabel(\"z[0]\")\n","    plt.ylabel(\"z[1]\")\n","    plt.imshow(figure, cmap='Greys_r')\n","    plt.savefig(filename)\n","    plt.show()\n","\n","\n","# MNIST dataset\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","image_size = x_train.shape[1]\n","original_dim = image_size * image_size\n","x_train = np.reshape(x_train, [-1, original_dim])\n","x_test = np.reshape(x_test, [-1, original_dim])\n","x_train = x_train.astype('float32') / 255\n","x_test = x_test.astype('float32') / 255\n","\n","# network parameters\n","input_shape = (original_dim, )\n","intermediate_dim = 512\n","batch_size = 128\n","latent_dim = 2\n","epochs = 50\n","\n","# VAE model = encoder + decoder\n","# build encoder model\n","inputs = Input(shape=input_shape, name='encoder_input')\n","x = Dense(intermediate_dim, activation='relu')(inputs)\n","z_mean = Dense(latent_dim, name='z_mean')(x)\n","z_log_var = Dense(latent_dim, name='z_log_var')(x)\n","\n","# use reparameterization trick to push the sampling out as input\n","# note that \"output_shape\" isn't necessary with the TensorFlow backend\n","z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n","\n","# instantiate encoder model\n","encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n","encoder.summary()\n","plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n","\n","# build decoder model\n","latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n","x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n","outputs = Dense(original_dim, activation='sigmoid')(x)\n","\n","# instantiate decoder model\n","decoder = Model(latent_inputs, outputs, name='decoder')\n","decoder.summary()\n","plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)\n","\n","# instantiate VAE model\n","outputs = decoder(encoder(inputs)[2])\n","vae = Model(inputs, outputs, name='vae_mlp')\n","\n","if __name__ == '__main__':\n","    # parser = argparse.ArgumentParser()\n","    # help_ = \"Load h5 model trained weights\"\n","    # parser.add_argument(\"-w\", \"--weights\", help=help_)\n","    # help_ = \"Use mse loss instead of binary cross entropy (default)\"\n","    # parser.add_argument(\"-m\",\n","    #                     \"--mse\",\n","    #                     help=help_, action='store_true')\n","    # args = parser.parse_args()\n","    models = (encoder, decoder)\n","    data = (x_test, y_test)\n","\n","    # VAE loss = mse_loss or xent_loss + kl_loss\n","    # if args.mse:\n","    #     reconstruction_loss = mse(inputs, outputs)\n","    # else:\n","    #     reconstruction_loss = binary_crossentropy(inputs,\n","    #                                               outputs)\n","    reconstruction_loss = binary_crossentropy(inputs,\n","                                                  outputs)\n"," \n","\n","    reconstruction_loss *= original_dim\n","    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n","    kl_loss = K.sum(kl_loss, axis=-1)\n","    kl_loss *= -0.5\n","    vae_loss = K.mean(reconstruction_loss + kl_loss)\n","    vae.add_loss(vae_loss)\n","    vae.compile(optimizer='adam')\n","    vae.summary()\n","    plot_model(vae,\n","               to_file='vae_mlp.png',\n","               show_shapes=True)\n","\n","    # if args.weights:\n","    #     vae.load_weights(args.weights)\n","    # else:\n","    #     # train the autoencoder\n","    #     vae.fit(x_train,\n","    #             epochs=epochs,\n","    #             batch_size=batch_size,\n","    #             validation_data=(x_test, None))\n","    #     vae.save_weights('vae_mlp_mnist.h5')\n","\n","    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0)\n","\n","    %tensorboard --logdir logs/fit\n","\n","\n","# train the autoencoder\n","    vae.fit(x_train,\n","           epochs=epochs,\n","           batch_size=batch_size,\n","           validation_data=(x_test, None),\n","           callbacks=[tensorboard_callback])\n","    vae.save_weights('vae_mlp_mnist.h5')\n","\n","\n","    plot_results(models,\n","                 data,\n","                 batch_size=batch_size,\n","                 model_name=\"vae_mlp\")\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"encoder\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","encoder_input (InputLayer)      [(None, 784)]        0                                            \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 512)          401920      encoder_input[0][0]              \n","__________________________________________________________________________________________________\n","z_mean (Dense)                  (None, 2)            1026        dense[0][0]                      \n","__________________________________________________________________________________________________\n","z_log_var (Dense)               (None, 2)            1026        dense[0][0]                      \n","__________________________________________________________________________________________________\n","z (Lambda)                      (None, 2)            0           z_mean[0][0]                     \n","                                                                 z_log_var[0][0]                  \n","==================================================================================================\n","Total params: 403,972\n","Trainable params: 403,972\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"decoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","z_sampling (InputLayer)      [(None, 2)]               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               1536      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 784)               402192    \n","=================================================================\n","Total params: 403,728\n","Trainable params: 403,728\n","Non-trainable params: 0\n","_________________________________________________________________\n","WARNING:tensorflow:Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n","Model: \"vae_mlp\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","encoder_input (InputLayer)      [(None, 784)]        0                                            \n","__________________________________________________________________________________________________\n","encoder (Model)                 [(None, 2), (None, 2 403972      encoder_input[0][0]              \n","__________________________________________________________________________________________________\n","decoder (Model)                 (None, 784)          403728      encoder[1][2]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 512)          1536        encoder[1][2]                    \n","__________________________________________________________________________________________________\n","tf_op_layer_decoder/dense_2/Mat [(None, 784)]        0           dense_1[1][0]                    \n","__________________________________________________________________________________________________\n","tf_op_layer_decoder/dense_2/Bia [(None, 784)]        0           tf_op_layer_decoder/dense_2/MatMu\n","__________________________________________________________________________________________________\n","tf_op_layer_logistic_loss/zeros [(None, 784)]        0           tf_op_layer_decoder/dense_2/BiasA\n","__________________________________________________________________________________________________\n","tf_op_layer_logistic_loss/Great [(None, 784)]        0           tf_op_layer_decoder/dense_2/BiasA\n","                                                                 tf_op_layer_logistic_loss/zeros_l\n","__________________________________________________________________________________________________\n","tf_op_layer_logistic_loss/Neg ( [(None, 784)]        0           tf_op_layer_decoder/dense_2/BiasA\n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 512)          401920      encoder_input[0][0]              \n","__________________________________________________________________________________________________\n","tf_op_layer_logistic_loss/Selec [(None, 784)]        0           tf_op_layer_logistic_loss/Greater\n","                                                                 tf_op_layer_logistic_loss/Neg[0][\n","                                                                 tf_op_layer_decoder/dense_2/BiasA\n","__________________________________________________________________________________________________\n","z_log_var (Dense)               (None, 2)            1026        dense[0][0]                      \n","__________________________________________________________________________________________________\n","z_mean (Dense)                  (None, 2)            1026        dense[0][0]                      \n","__________________________________________________________________________________________________\n","tf_op_layer_logistic_loss/Selec [(None, 784)]        0           tf_op_layer_logistic_loss/Greater\n","                                                                 tf_op_layer_decoder/dense_2/BiasA\n","                                                                 tf_op_layer_logistic_loss/zeros_l\n","__________________________________________________________________________________________________\n","tf_op_layer_logistic_loss/mul ( [(None, 784)]        0           tf_op_layer_decoder/dense_2/BiasA\n","                                                                 encoder_input[0][0]              \n","__________________________________________________________________________________________________\n","tf_op_layer_logistic_loss/Exp ( [(None, 784)]        0           tf_op_layer_logistic_loss/Select_\n","__________________________________________________________________________________________________\n","tf_op_layer_add (TensorFlowOpLa [(None, 2)]          0           z_log_var[0][0]                  \n","__________________________________________________________________________________________________\n","tf_op_layer_Square (TensorFlowO [(None, 2)]          0           z_mean[0][0]                     \n","__________________________________________________________________________________________________\n","tf_op_layer_logistic_loss/sub ( [(None, 784)]        0           tf_op_layer_logistic_loss/Select[\n","                                                                 tf_op_layer_logistic_loss/mul[0][\n","__________________________________________________________________________________________________\n","tf_op_layer_logistic_loss/Log1p [(None, 784)]        0           tf_op_layer_logistic_loss/Exp[0][\n","__________________________________________________________________________________________________\n","tf_op_layer_sub (TensorFlowOpLa [(None, 2)]          0           tf_op_layer_add[0][0]            \n","                                                                 tf_op_layer_Square[0][0]         \n","__________________________________________________________________________________________________\n","tf_op_layer_Exp (TensorFlowOpLa [(None, 2)]          0           z_log_var[0][0]                  \n","__________________________________________________________________________________________________\n","tf_op_layer_logistic_loss (Tens [(None, 784)]        0           tf_op_layer_logistic_loss/sub[0][\n","                                                                 tf_op_layer_logistic_loss/Log1p[0\n","__________________________________________________________________________________________________\n","tf_op_layer_sub_1 (TensorFlowOp [(None, 2)]          0           tf_op_layer_sub[0][0]            \n","                                                                 tf_op_layer_Exp[0][0]            \n","__________________________________________________________________________________________________\n","tf_op_layer_Mean (TensorFlowOpL [(None,)]            0           tf_op_layer_logistic_loss[0][0]  \n","__________________________________________________________________________________________________\n","tf_op_layer_Sum (TensorFlowOpLa [(None,)]            0           tf_op_layer_sub_1[0][0]          \n","__________________________________________________________________________________________________\n","tf_op_layer_mul (TensorFlowOpLa [(None,)]            0           tf_op_layer_Mean[0][0]           \n","__________________________________________________________________________________________________\n","tf_op_layer_mul_1 (TensorFlowOp [(None,)]            0           tf_op_layer_Sum[0][0]            \n","__________________________________________________________________________________________________\n","tf_op_layer_add_1 (TensorFlowOp [(None,)]            0           tf_op_layer_mul[0][0]            \n","                                                                 tf_op_layer_mul_1[0][0]          \n","__________________________________________________________________________________________________\n","tf_op_layer_Mean_1 (TensorFlowO [()]                 0           tf_op_layer_add_1[0][0]          \n","__________________________________________________________________________________________________\n","add_loss (AddLoss)              ()                   0           tf_op_layer_Mean_1[0][0]         \n","==================================================================================================\n","Total params: 807,700\n","Trainable params: 807,700\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["Reusing TensorBoard on port 6006 (pid 2607), started 0:04:42 ago. (Use '!kill 2607' to kill it.)"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["\n","        (async () => {\n","            const url = await google.colab.kernel.proxyPort(6006, {\"cache\": true});\n","            const iframe = document.createElement('iframe');\n","            iframe.src = url;\n","            iframe.setAttribute('width', '100%');\n","            iframe.setAttribute('height', '800');\n","            iframe.setAttribute('frameborder', 0);\n","            document.body.appendChild(iframe);\n","        })();\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/50\n","60000/60000 [==============================] - 11s 176us/sample - loss: 195.0003 - val_loss: 171.1844\n","Epoch 2/50\n","60000/60000 [==============================] - 11s 177us/sample - loss: 168.0297 - val_loss: 166.1747\n","Epoch 3/50\n","60000/60000 [==============================] - 10s 175us/sample - loss: 164.7456 - val_loss: 163.6990\n","Epoch 4/50\n","60000/60000 [==============================] - 11s 176us/sample - loss: 162.8510 - val_loss: 162.3138\n","Epoch 5/50\n","60000/60000 [==============================] - 11s 178us/sample - loss: 161.3600 - val_loss: 160.9236\n","Epoch 6/50\n","60000/60000 [==============================] - 11s 178us/sample - loss: 159.9319 - val_loss: 159.6221\n","Epoch 7/50\n","60000/60000 [==============================] - 11s 177us/sample - loss: 158.7542 - val_loss: 158.6456\n","Epoch 8/50\n","60000/60000 [==============================] - 11s 177us/sample - loss: 157.7264 - val_loss: 157.6642\n","Epoch 9/50\n","60000/60000 [==============================] - 15s 255us/sample - loss: 156.7427 - val_loss: 156.9182\n","Epoch 10/50\n","60000/60000 [==============================] - 11s 179us/sample - loss: 155.8310 - val_loss: 156.0744\n","Epoch 11/50\n","60000/60000 [==============================] - 11s 177us/sample - loss: 155.0883 - val_loss: 155.4426\n","Epoch 12/50\n","60000/60000 [==============================] - 11s 176us/sample - loss: 154.4455 - val_loss: 154.8856\n","Epoch 13/50\n","60000/60000 [==============================] - 11s 176us/sample - loss: 153.8393 - val_loss: 154.5657\n","Epoch 14/50\n","60000/60000 [==============================] - 11s 177us/sample - loss: 153.3053 - val_loss: 154.1308\n","Epoch 15/50\n","60000/60000 [==============================] - 11s 177us/sample - loss: 152.8587 - val_loss: 153.9109\n","Epoch 16/50\n","60000/60000 [==============================] - 11s 178us/sample - loss: 152.4590 - val_loss: 153.5311\n","Epoch 17/50\n","60000/60000 [==============================] - 11s 176us/sample - loss: 152.0789 - val_loss: 153.0862\n","Epoch 18/50\n","60000/60000 [==============================] - 11s 175us/sample - loss: 151.6600 - val_loss: 152.8536\n","Epoch 19/50\n","60000/60000 [==============================] - 11s 175us/sample - loss: 151.3535 - val_loss: 152.7745\n","Epoch 20/50\n","60000/60000 [==============================] - 11s 176us/sample - loss: 151.0654 - val_loss: 152.6799\n","Epoch 21/50\n","60000/60000 [==============================] - 11s 177us/sample - loss: 150.7408 - val_loss: 152.2893\n","Epoch 22/50\n","60000/60000 [==============================] - 11s 176us/sample - loss: 150.5172 - val_loss: 152.0072\n","Epoch 23/50\n","60000/60000 [==============================] - 11s 177us/sample - loss: 150.1959 - val_loss: 152.0628\n","Epoch 24/50\n","60000/60000 [==============================] - 11s 180us/sample - loss: 150.0201 - val_loss: 151.9794\n","Epoch 25/50\n","60000/60000 [==============================] - 11s 178us/sample - loss: 149.7882 - val_loss: 151.5497\n","Epoch 26/50\n","60000/60000 [==============================] - 11s 179us/sample - loss: 149.5845 - val_loss: 151.8485\n","Epoch 27/50\n","60000/60000 [==============================] - 11s 181us/sample - loss: 149.3764 - val_loss: 151.5792\n","Epoch 28/50\n","60000/60000 [==============================] - 11s 180us/sample - loss: 149.1813 - val_loss: 151.5594\n","Epoch 29/50\n","60000/60000 [==============================] - 11s 180us/sample - loss: 148.9996 - val_loss: 151.5926\n","Epoch 30/50\n","60000/60000 [==============================] - 11s 182us/sample - loss: 148.8527 - val_loss: 151.3546\n","Epoch 31/50\n","60000/60000 [==============================] - 11s 181us/sample - loss: 148.7095 - val_loss: 151.2617\n","Epoch 32/50\n","60000/60000 [==============================] - 11s 182us/sample - loss: 148.5015 - val_loss: 151.0516\n","Epoch 33/50\n","60000/60000 [==============================] - 11s 179us/sample - loss: 148.3973 - val_loss: 151.2099\n","Epoch 34/50\n","60000/60000 [==============================] - 11s 181us/sample - loss: 148.1811 - val_loss: 151.1324\n","Epoch 35/50\n","60000/60000 [==============================] - 11s 182us/sample - loss: 148.1155 - val_loss: 150.8454\n","Epoch 36/50\n","60000/60000 [==============================] - 11s 181us/sample - loss: 147.9928 - val_loss: 151.0152\n","Epoch 37/50\n","60000/60000 [==============================] - 11s 180us/sample - loss: 147.8536 - val_loss: 150.7915\n","Epoch 38/50\n","60000/60000 [==============================] - 11s 184us/sample - loss: 147.7373 - val_loss: 150.6567\n","Epoch 39/50\n","60000/60000 [==============================] - 11s 182us/sample - loss: 147.5998 - val_loss: 150.7190\n","Epoch 40/50\n","60000/60000 [==============================] - 11s 181us/sample - loss: 147.5233 - val_loss: 150.5776\n","Epoch 41/50\n","60000/60000 [==============================] - 11s 181us/sample - loss: 147.3740 - val_loss: 151.0189\n","Epoch 42/50\n","60000/60000 [==============================] - 11s 182us/sample - loss: 147.2756 - val_loss: 150.8745\n","Epoch 43/50\n","60000/60000 [==============================] - 11s 182us/sample - loss: 147.1879 - val_loss: 150.6188\n","Epoch 44/50\n","60000/60000 [==============================] - 11s 184us/sample - loss: 147.0753 - val_loss: 150.6365\n","Epoch 45/50\n","28544/60000 [=============>................] - ETA: 5s - loss: 146.8423"],"name":"stdout"}]}]}